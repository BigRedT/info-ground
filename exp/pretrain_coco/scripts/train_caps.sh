python -m exp.pretrain_coco.run.train_caps \
    --exp_name 'self_lang_sup_train_batch_size_200' \
    --model_num -1 \
    --lr 1e-5 \
    --train_batch_size 50